{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# RAG approach to answer questions using flan-ul2 from watsonx.ai and Langchain\n"}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook contains the steps and code to answer questions using the flan-ul2 Foundation Model from watsonx.ai and Langchain. The data is about the company policies of a fictitious company, and is synthetically generated. There are numerous articles about RAG on the internet and is not covered in the notebook. This notebook is to be executed first to get an handle on the data and the RAG approach, followed by the evaluation and chunking techniques.\n\n## Contents\nThis notebooks contains the following:\n1. Setup of required libraries and modules\n2. Data Loading, pay attention to chunk size and overlap\n3. Accessing LLM from WML\n4. Answering the question using RAG approach"}, {"metadata": {}, "cell_type": "markdown", "source": "## Install the dependencies"}, {"metadata": {}, "cell_type": "markdown", "source": "Before starting this step, ensure that the Watson Machine Learning service is created and associated with this project. It might take few minutes to install all the dependencies."}, {"metadata": {}, "cell_type": "code", "source": "!pip install \"ibm-watson-machine-learning>=1.0.320\" \n!pip install \"pydantic>=1.10.0\" \n!pip install langchain \n!pip install huggingface\n!pip install huggingface-hub\n!pip install sentence-transformers\n!pip install chromadb", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: ibm-watson-machine-learning>=1.0.320 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.0.326)\nRequirement already satisfied: pandas<1.6.0,>=0.24.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (1.4.3)\nRequirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (2.12.0)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (0.3.3)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (2023.7.22)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (0.8.10)\nRequirement already satisfied: importlib-metadata in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (4.11.3)\nRequirement already satisfied: packaging in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (21.3)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (1.26.11)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning>=1.0.320) (2.31.0)\nRequirement already satisfied: jmespath<1.0.0,>=0.10.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning>=1.0.320) (0.10.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning>=1.0.320) (2.12.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning>=1.0.320) (2.12.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk-core==2.12.0->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning>=1.0.320) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas<1.6.0,>=0.24.2->ibm-watson-machine-learning>=1.0.320) (2022.1)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas<1.6.0,>=0.24.2->ibm-watson-machine-learning>=1.0.320) (1.23.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->ibm-watson-machine-learning>=1.0.320) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->ibm-watson-machine-learning>=1.0.320) (3.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from importlib-metadata->ibm-watson-machine-learning>=1.0.320) (3.8.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from lomond->ibm-watson-machine-learning>=1.0.320) (1.16.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging->ibm-watson-machine-learning>=1.0.320) (3.0.9)\nCollecting pydantic>=1.10.0\n  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typing-extensions>=4.6.1\n  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\nCollecting annotated-types>=0.4.0\n  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\nCollecting pydantic-core==2.10.1\n  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: typing-extensions, annotated-types, pydantic-core, pydantic\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.3.0\n    Uninstalling typing_extensions-4.3.0:\n      Successfully uninstalled typing_extensions-4.3.0\nSuccessfully installed annotated-types-0.6.0 pydantic-2.4.2 pydantic-core-2.10.1 typing-extensions-4.8.0\nCollecting langchain\n  Downloading langchain-0.0.315-py3-none-any.whl (1.9 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from langchain) (4.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from langchain) (1.4.39)\nCollecting anyio<4.0\n  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from langchain) (2.31.0)\nCollecting langsmith<0.1.0,>=0.0.43\n  Downloading langsmith-0.0.43-py3-none-any.whl (40 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from langchain) (1.23.1)\nCollecting jsonpatch<2.0,>=1.33\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from langchain) (3.8.5)\nCollecting dataclasses-json<0.7,>=0.5.7\n  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from langchain) (2.4.2)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from langchain) (6.0)\nCollecting tenacity<9.0.0,>=8.1.0\n  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (5.2.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.3)\nCollecting sniffio>=1.1\n  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\nCollecting exceptiongroup\n  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\nRequirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from async-timeout<5.0.0,>=4.0.0->langchain) (4.8.0)\nCollecting marshmallow<4.0.0,>=3.18.0\n  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typing-inspect<1,>=0.4.0\n  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n", "name": "stdout"}, {"output_type": "stream", "text": "Collecting jsonpointer>=1.9\n  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.10.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.11)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.0.9)\nInstalling collected packages: typing-inspect, tenacity, sniffio, jsonpointer, exceptiongroup, marshmallow, jsonpatch, anyio, langsmith, dataclasses-json, langchain\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 8.0.1\n    Uninstalling tenacity-8.0.1:\n      Successfully uninstalled tenacity-8.0.1\nSuccessfully installed anyio-3.7.1 dataclasses-json-0.6.1 exceptiongroup-1.1.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.315 langsmith-0.0.43 marshmallow-3.20.1 sniffio-1.3.0 tenacity-8.2.3 typing-inspect-0.9.0\nCollecting huggingface\n  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\nInstalling collected packages: huggingface\nSuccessfully installed huggingface-0.0.1\nCollecting huggingface-hub\n  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fsspec>=2023.5.0\n  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub) (4.64.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub) (4.8.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub) (6.0)\nCollecting filelock\n  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->huggingface-hub) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->huggingface-hub) (2023.7.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->huggingface-hub) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.11)\nInstalling collected packages: fsspec, filelock, huggingface-hub\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2021.10.1\n    Uninstalling fsspec-2021.10.1:\n      Successfully uninstalled fsspec-2021.10.1\nSuccessfully installed filelock-3.12.4 fsspec-2023.9.2 huggingface-hub-0.18.0\nCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sentence-transformers) (4.64.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sentence-transformers) (1.12.1)\nRequirement already satisfied: torchvision in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sentence-transformers) (0.13.1)\nRequirement already satisfied: numpy in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sentence-transformers) (1.23.1)\nRequirement already satisfied: scikit-learn in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sentence-transformers) (1.1.1)\nRequirement already satisfied: scipy in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sentence-transformers) (1.8.1)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sentence-transformers) (0.1.96)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sentence-transformers) (0.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.9.2)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: filelock in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\nCollecting tokenizers<0.15,>=0.14\n  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting regex!=2019.12.17\n  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting safetensors>=0.3.1\n  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: click in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.0.4)\nRequirement already satisfied: joblib in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.1.1)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nCollecting huggingface-hub>=0.4.0\n  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=6fa551a0fe3fd629c44833472637f1f1040a3e9a10a34b9793d0fcb56b63ad0a\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: safetensors, regex, nltk, huggingface-hub, tokenizers, transformers, sentence-transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.18.0\n    Uninstalling huggingface-hub-0.18.0:\n      Successfully uninstalled huggingface-hub-0.18.0\nSuccessfully installed huggingface-hub-0.17.3 nltk-3.8.1 regex-2023.10.3 safetensors-0.4.0 sentence-transformers-2.2.2 tokenizers-0.14.1 transformers-4.34.0\nCollecting chromadb\n  Downloading chromadb-0.4.14-py3-none-any.whl (448 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting uvicorn[standard]>=0.18.3\n  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting onnxruntime>=1.14.1\n  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting bcrypt>=4.0.1\n  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fastapi>=0.95.2\n  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tqdm>=4.65.0\n  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from chromadb) (1.23.1)\nCollecting overrides>=7.3.1\n  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\nRequirement already satisfied: pydantic>=1.9 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from chromadb) (2.4.2)\nRequirement already satisfied: requests>=2.28 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from chromadb) (2.31.0)\nCollecting chroma-hnswlib==0.7.3\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting typer>=0.9.0\n  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from chromadb) (4.8.0)\nCollecting pulsar-client>=3.1.0\n  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from chromadb) (0.14.1)\nCollecting pypika>=0.48.9\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting posthog>=2.4.0\n  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\nCollecting importlib-resources\n  Downloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)\nCollecting grpcio>=1.58.0\n  Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting starlette<0.28.0,>=0.27.0\n  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\nRequirement already satisfied: packaging in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (21.3)\nCollecting sympy\n  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.19.6)\nCollecting coloredlogs\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: flatbuffers in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\nRequirement already satisfied: python-dateutil>2.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\nCollecting backoff>=1.10.0\n  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\nCollecting monotonic>=1.5\n  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\nRequirement already satisfied: pydantic-core==2.10.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.10.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests>=2.28->chromadb) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests>=2.28->chromadb) (1.26.11)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.17.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.0.4)\nCollecting h11>=0.8\n  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-dotenv>=0.13\n  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\nCollecting httptools>=0.5.0\n  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting watchfiles>=0.13\n  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n  Downloading uvloop-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting websockets>=10.4\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\nRequirement already satisfied: filelock in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.4)\nRequirement already satisfied: fsspec in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.9.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging->onnxruntime>=1.14.1->chromadb) (3.0.9)\nCollecting humanfriendly>=9.1\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mpmath>=0.19\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53738 sha256=f7f393a32d788eadf97a93a79016fbe9acf92bd97e505ad63c79fae0aab6de79\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\nSuccessfully built pypika\nInstalling collected packages: pypika, mpmath, monotonic, websockets, uvloop, typer, tqdm, sympy, python-dotenv, pulsar-client, overrides, importlib-resources, humanfriendly, httptools, h11, grpcio, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, starlette, posthog, coloredlogs, onnxruntime, fastapi, chromadb\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.64.0\n    Uninstalling tqdm-4.64.0:\n      Successfully uninstalled tqdm-4.64.0\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.42.0\n    Uninstalling grpcio-1.42.0:\n      Successfully uninstalled grpcio-1.42.0\nSuccessfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.14 coloredlogs-15.0.1 fastapi-0.103.2 grpcio-1.59.0 h11-0.14.0 httptools-0.6.0 humanfriendly-10.0 importlib-resources-6.1.0 monotonic-1.6 mpmath-1.3.0 onnxruntime-1.16.1 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 sympy-1.12 tqdm-4.66.1 typer-0.9.0 uvicorn-0.23.2 uvloop-0.18.0 watchfiles-0.21.0 websockets-11.0.3\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## WatsonX.ai API Connection"}, {"metadata": {}, "cell_type": "markdown", "source": "Provide the Cloud IAM key to access the foundation models from the WML endpoint"}, {"metadata": {}, "cell_type": "code", "source": "import os, getpass\ncredentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n}", "execution_count": 1, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Please enter your WML api key (hit enter): \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Project Id definition"}, {"metadata": {}, "cell_type": "markdown", "source": "The foundation models need project id for the execution and also for the CUH"}, {"metadata": {}, "cell_type": "code", "source": "try:\n    project_id = os.environ[\"PROJECT_ID\"]\n    \nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!pip install wget\nimport wget\n\nfilename = 'companyPolicies.txt'\nurl = 'https://raw.github.com/ravisrirangam/chunking_techniques/main/data/companypolicies.txt'\n\nwget.download(url, out=filename)\nprint('file downloaded')", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: wget in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (3.2)\nfile downloaded\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Data Loading "}, {"metadata": {}, "cell_type": "markdown", "source": "Langchain is used to split the document and create chunks. The chunk size is mentioned as 1000 in this notebook and in the subsequent notebooks, I'll show how to determine the optimal chunking technique. Though the chunk size is mentioned as 1000, the splitting is happening randomly, it's an issue with Langchain."}, {"metadata": {}, "cell_type": "code", "source": "from langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\nloader = TextLoader(filename)\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.split_documents(documents)\nprint(len(texts))", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "Created a chunk of size 1624, which is longer than the specified 1000\nCreated a chunk of size 1885, which is longer than the specified 1000\nCreated a chunk of size 1903, which is longer than the specified 1000\nCreated a chunk of size 1729, which is longer than the specified 1000\nCreated a chunk of size 1678, which is longer than the specified 1000\nCreated a chunk of size 2032, which is longer than the specified 1000\nCreated a chunk of size 1894, which is longer than the specified 1000\n", "name": "stderr"}, {"output_type": "stream", "text": "16\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Create an embedding model, using default from Hugging Face"}, {"metadata": {}, "cell_type": "markdown", "source": "The below code creates a default embedding model from HF and ingests them to Chromadb. Since, the focus is on chunking, not much focus is on embedding models"}, {"metadata": {}, "cell_type": "code", "source": "from langchain.embeddings import HuggingFaceEmbeddings\n\nembeddings = HuggingFaceEmbeddings()\ndocsearch = Chroma.from_documents(texts, embeddings)\nprint('documents ingested')", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6280421d184844a1b7f980502987d088"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "aab76f2d6fe64948889ea4345a940130"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c98c0662289e4522b6196a37ef6ed8d1"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "33bd01101b2a46d495a7c57e1b957df8"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a0a8b27aec074355beee64bc00c27927"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "26db5a7b517c4ba8bc9f48d01d1fc1c4"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "dc6b826a02ca413b9ccb3b002e21f1ff"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8de25c91edbb47169ef34f187a2ef8e3"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ea0ab52d1b634baabd05c8bfff6e6528"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c3a3e209176a465f9132174204b4516f"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d85304adb6db4a598b03671614895353"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0f14936a657744d182c78a9cb6741992"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5ca8e49d5c1c40a9881e98554e2d329b"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading (\u2026)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "19653c5d359244148263d945b3e61b2c"}}, "metadata": {}}, {"output_type": "stream", "text": "documents ingested\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## flan-ul2 creation"}, {"metadata": {}, "cell_type": "markdown", "source": "The below code does the following:\n1. Get the model_id\n2. Create the parameters for the model\n3. Initialize the model\n4. Langchain wrapper for the model"}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n\nmodel_id = ModelTypes.FLAN_UL2", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The decoding method is set to \"greedy\" to get a deterministic output, you can change it to \"sample\" and add temperature, top_k and top_p parameters"}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\nfrom ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n\nparameters = {\n    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n    GenParams.MIN_NEW_TOKENS: 130,\n    GenParams.MAX_NEW_TOKENS: 200\n}", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models import Model\n\nmodel = Model(\n    model_id=model_id,\n    params=parameters,\n    credentials=credentials,\n    project_id=project_id\n)", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n\nflan_ul2_llm = WatsonxLLM(model=model)", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Get Answer to a question on one policy using RAG"}, {"metadata": {}, "cell_type": "markdown", "source": "Retrieving the chunks from chromadb is abstracted in the below code and will be discussed in the next section. PromptTemplate is also not used and the summary generated is also not complete. The code is for illustrative purpose and the parameters can be modified to get the deisred outcome."}, {"metadata": {}, "cell_type": "code", "source": "from langchain.chains import RetrievalQA\n\nqa = RetrievalQA.from_chain_type(llm=flan_ul2_llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())\nquery = \"mobile policy\"\nqa.run(query)", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "\"Yes, it helps to promote the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices. Internet and Email Policy Our Internet and Email Policy is established to guide the responsible and secure use of these essential tools within our organization. We recognize their significance in daily business operations and the importance of adhering to principles that maintain security, productivity, and legal compliance. Acceptable Use: Company-provided internet and email services are primarily meant for job-related tasks. Limited personal use is allowed during non-work hours, provided it doesn't interfere with work responsibilities. Security: Safeguard your login credentials, avoiding the sharing of passwords. Exercise caution with email attachments and links from unknown sources. Promptly report any unusual online activity or potential security breaches. Confidentiality: Reserve email for the\""}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Query on ChromaDB"}, {"metadata": {}, "cell_type": "markdown", "source": "If a native query was run on ChromaDB with \"mobile policy\", it can be noticed that 4 chunks have been retrieved. The first two chunks are matching the query and are the correct chunks. The next two chunks are not relevant to the query but had some semantic match and were returned in the query result. The LLM picked up the correct chunks and generated the summary of the content."}, {"metadata": {}, "cell_type": "code", "source": "query = \"mobile policy\"\ndocs = docsearch.similarity_search(query)\nprint(len(docs))\nfor i in range(len(docs)):\n    print(docs[i].page_content)\n    print('\\n\\n')\n", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "4\n4.\tMobile Phone Policy\n\n\n\nThe Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\nAcceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\nSecurity: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\nConfidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.\nCost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\nCompliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\nLost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\nConsequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\nThe Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices.\n\n\n\n3.\tInternet and Email Policy\n\n\n\nOur Internet and Email Policy is established to guide the responsible and secure use of these essential tools within our organization. We recognize their significance in daily business operations and the importance of adhering to principles that maintain security, productivity, and legal compliance.\nAcceptable Use: Company-provided internet and email services are primarily meant for job-related tasks. Limited personal use is allowed during non-work hours, provided it doesn't interfere with work responsibilities.\nSecurity: Safeguard your login credentials, avoiding the sharing of passwords. Exercise caution with email attachments and links from unknown sources. Promptly report any unusual online activity or potential security breaches.\nConfidentiality: Reserve email for the transmission of confidential information, trade secrets, and sensitive customer data only when encryption is applied. Exercise discretion when discussing company matters on public forums or social media.\nHarassment and Inappropriate Content: Internet and email usage must not involve harassment, discrimination, or the distribution of offensive or inappropriate content. Show respect and sensitivity to others in all online communications.\nCompliance: Ensure compliance with all relevant laws and regulations regarding internet and email usage, including those related to copyright and data protection.\nMonitoring: The company retains the right to monitor internet and email usage for security and compliance purposes.\nConsequences: Policy violations may lead to disciplinary measures, including potential termination.\nOur Internet and Email Policy aims to promote safe, responsible usage of digital communication tools that align with our values and legal obligations. Each employee is expected to understand and follow this policy. Regular reviews ensure its alignment with evolving technology and security standards.\n\n\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}